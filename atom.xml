<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title><![CDATA[zf2timo dev notes]]></title>
    <link href="/atom.xml" rel="self"/>
    <link href="/"/>
    <updated>2018-10-26T10:03:18+02:00</updated>
    <id>/</id>
        <generator uri="http://sculpin.io/">Sculpin</generator>
            <entry>
            <title type="html"><![CDATA[Empty server name in XDEBUG]]></title>
            <link href="/blog/2017/12/14/empty-server-name-in-xdebug"/>
            <updated>2017-12-14T00:00:00+01:00</updated>
            <id>/blog/2017/12/14/empty-server-name-in-xdebug</id>
            <content type="html"><![CDATA[<h1 id="empty-server-name-in-xdebug">Empty server name in XDEBUG</h1>

<p>Today I build a new docker environment for a project with a really simple setup. All I needed
was a php and nginx container. 
I had both created for other projects several times without big issues.
But as I started to debug the application, PHPStorm wasn't able to map the remote directory to a local directory.
For the first debug session this is normal and you have to configure this manually.</p>

<p>But this time I had another message in my debug window:</p>

<p><img src="/images/posts/2017-12-14-debug-error-window.png" alt="PHPStorm debug window with error" title="PHPStorm Debug window" /></p>

<p>While checking my PHPStorm configuration I noticed a Server without a name in the "Run\Debug configurations > Servers" window.
I did not created a config like this one.</p>

<p>After some research on the internet I finally found the solution:
My NGINX did not send a Server name in the response. For this reason my IDE was not able to create a proper configuration and 
map the local directories to remote directories.</p>

<p>To Fix the problem only a single line was missing in my <code>/etc/nginx/sites-available/default.conf</code></p>

<pre><code class="nginx">fastcgi_param SERVER_NAME $server_name;
</code></pre>

<p>With this configuration the debugging works smooth as usually.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Delete old git branches]]></title>
            <link href="/blog/2017/01/16/delete-old-git-branches"/>
            <updated>2017-01-16T00:00:00+01:00</updated>
            <id>/blog/2017/01/16/delete-old-git-branches</id>
            <content type="html"><![CDATA[<h1 id="delete-old-git-branches">Delete old git branches</h1>

<p>When working with git you <s>should</s> have to use branches. But over the time, there will be a lot of branches that
arn't needed anymore.</p>

<p>To get rid of this waste, i created a script to delete them:</p>

<pre><code class="bash">#!/usr/bin/env bash

BRANCHES="$(git branch --merged | grep -v "\*" | grep -v "master" | grep -v "develop")"

if [ -z $BRANCHES ]; then
    echo "No branch can deleted safely"
    exit 1;
fi

echo "The following branches will be deleted:"
echo $BRANCHES
echo "Are you sure? (y or n)"
read ANSWER

if [ $ANSWER = "y" ]; then
    echo $BRANCHES | xargs -n 1 git branch -d
fi
</code></pre>

<p>It selects all branches which are merged into master branch and after a confirmation, they will be deleted.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Automatically updating host file]]></title>
            <link href="/blog/2016/11/20/automatically-updating-host-file"/>
            <updated>2016-11-20T00:00:00+01:00</updated>
            <id>/blog/2016/11/20/automatically-updating-host-file</id>
            <content type="html"><![CDATA[<h1 id="make-the-internet-green-again">Make the internet green again</h1>

<p>These days most of the internet users use Browser Plugins to block supsicious ad and/or prevent tracking mechanism or similar from working. The most popular plugins are AdBlocker Plus UBlock, NoScript, Privacy Badger - just to name a few. A bit disadvantageous of using your plugin of choice is the mandatory installation in every browser that is used - and therefor additionally settings have to be made several times. Can be a bit stressfull when you ask me.</p>

<p>An alternative way to block suspicious servers is to make use of local host files and redirect the requests to the localhost. But with the huge amount of ad-, tracking- and other mistrustful servers out there it would take a lot of time and effort to to keep the <code>host</code> file up to date.</p>

<p>Thankfully <a href="http://someonewhocares.org">Dan Pollock</a> has done this or rather is still updating the list of mistrustful servers multiple times a week. And thankfully he allows everyone to use this file.</p>

<p>With a few commands on Linux operating system this process of updating can be automated:</p>

<pre><code class="bash">wget -O someonewhocares.hosts http://someonewhocares.org/hosts/hosts; cat someonewhocares.hosts /etc/hosts | grep -v -e "^[[:space:]]*$" | grep -v -e "^#" | sort | uniq &gt; /etc/hosts; rm someonewhocares.hosts
</code></pre>

<p>This is a really long command, which we don't like to enter every time a new version of the list is published. Therefore let us automate the process with a cronjob:</p>

<pre><code class="bash">52,22 */4 * * * wget -O someonewhocares.hosts http://someonewhocares.org/hosts/hosts; cat someonewhocares.hosts /etc/hosts | grep -v -e "^[[:space:]]*$" | grep -v -e "^#" | sort | uniq &gt; /etc/hosts; rm someonewhocares.hosts &gt;&gt; /var/log/cron-host-file-update.log 2&gt;&amp;1
</code></pre>

<p>Please note that this cronjob has to be registered for the root user. Other users can not write to the <code>host</code> file by default.
Also the time schedule should match you're usage behaviour.</p>

<p>I think, this is a easy solution to block odd server.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Blog publishing on Github with Sculpin]]></title>
            <link href="/blog/2016/10/07/blog-publishing-on-github-with-sculpin"/>
            <updated>2016-10-07T00:00:00+02:00</updated>
            <id>/blog/2016/10/07/blog-publishing-on-github-with-sculpin</id>
            <content type="html"><![CDATA[<p>There is a great feature on Github to easily publish a static HTML Page on its servers - like this one you are currently 
reading on. Read through my documentation to find out what my setup and publishing process looks like.</p>

<h2 id="generating-the-static-page">Generating the static Page</h2>

<p>A perfect addition to Github Sites are static Site generators. These tools convert markdown files into HTML files. 
Github promotes Jekyll as a site generator, but you have to hassle with Ruby, therefore I decided to use <a href="https://sculpin.io/">Sculpin</a>,
which is written in PHP that is already installed on all of my Workstations. And I am the most experienced with PHP.</p>

<p>After the installation via composer a local server can be started to watch the changes:</p>

<pre><code class="bash">$ ./vendor/bin/sculpin generate --watch --server
</code></pre>

<p>This server can be accessed via <a href="http://localhost:8000">localhost:8000</a> to view the latest version of the site.
If a change is made in the layout or a post, sculpin re-generates the site automatically for you.</p>

<p>When it's done, new repositories are needed on Github.</p>

<h2 id="preparations-and-limitations">Preparations and Limitations</h2>

<p>The site will be published in an own Repository with a defined naming scheme. These have to be <code>$username.github.io</code> - 
in my case it's <a href="zf2timo.github.io"><code>zf2timo.github.io</code></a>. This name is also the domain name to browse through the blog.</p>

<p>Since I have a simple user Account, the source of the Site has to be in the root of the master branch. There are 
<a href="https://help.github.com/articles/user-organization-and-project-pages/">also options</a> to publish into a sub-folder, 
but these are only available for organisations.
But as I wanted to have the generated site separated from the configuration files for sculpin, too, I had to look 
for another way. 
I found the solution in creating another repository - named <a href="https://github.com/zf2timo/blog-generator"><code>blog-generator</code></a> - 
where all the files for sculpins are versioned.</p>

<p>Now it's time to combine these two repositories.</p>

<h2 id="publishing-to-github">Publishing to Github</h2>

<p>My process to publish the blog involves the following steps:</p>

<ul>
<li>switching to the repository <code>blog-generator</code></li>
<li>cloning the <code>zf2timo.github.io</code> repository in a sub-folder, when its not exists</li>
<li>generating the new html files with <code>sculpin</code></li>
<li>copying them into the <code>zf2timo.github.io</code> folder</li>
<li>switching in the sub-folder of <code>zf2timo.github.io</code></li>
<li>committing and pushing all changes to Github</li>
</ul>

<p>In the moment of pushing, the updated version is published (I am sure, there are running some tasks in the background 
on Github, but I didn't noticed a delay yet).</p>

<p>Because this are always the sames steps, I created the <a href="https://github.com/zf2timo/blog-generator/blob/b0aaf4f08963f42aabe24fde3b4e1952fb7e5d79/publish.sh"><code>publish.sh</code></a> 
file, that do all this steps for me and I just have to execute it.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[PHP xdebug in docker container]]></title>
            <link href="/blog/2016/09/23/php-xdebug-in-docker-container"/>
            <updated>2016-09-23T00:00:00+02:00</updated>
            <id>/blog/2016/09/23/php-xdebug-in-docker-container</id>
            <content type="html"><![CDATA[<p>When you are using Docker as a development environment, you face the situation to debug your php code with xdebug soon
or later.
All yo need to do, is to change your <code>Dockerfile</code> of your php container like this:</p>

<pre><code class="dockerfile">FROM php:7.0-fpm

RUN docker-php-ext-install pdo_mysql \
    &amp;&amp; docker-php-ext-install json

RUN pecl install xdebug
RUN docker-php-ext-enable xdebug
RUN sed -i '1 a xdebug.remote_autostart=true' /usr/local/etc/php/conf.d/docker-php-ext-xdebug.ini
RUN sed -i '1 a xdebug.remote_mode=req' /usr/local/etc/php/conf.d/docker-php-ext-xdebug.ini
RUN sed -i '1 a xdebug.remote_handler=dbgp' /usr/local/etc/php/conf.d/docker-php-ext-xdebug.ini
RUN sed -i '1 a xdebug.remote_connect_back=1 ' /usr/local/etc/php/conf.d/docker-php-ext-xdebug.ini
RUN sed -i '1 a xdebug.remote_port=9000' /usr/local/etc/php/conf.d/docker-php-ext-xdebug.ini
RUN sed -i '1 a xdebug.remote_host=192.168.0.196' /usr/local/etc/php/conf.d/docker-php-ext-xdebug.ini
RUN sed -i '1 a xdebug.remote_enable=1' /usr/local/etc/php/conf.d/docker-php-ext-xdebug.ini
</code></pre>

<p>If your container was already running, you have to stop it and start it again</p>

<pre><code class="bash">$ for id in $(sudo docker ps | grep -v CONTAINER | awk '{print $1}') ; do sudo docker stop $id ; done
$ sudo docker-compose up -d
</code></pre>

<p>And that's it.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Supporting Zend ServiceManager Factories for V2 and V3]]></title>
            <link href="/blog/2016/09/04/Supporting-Zend-Service-Manager-Factories-for-V2-and-V3"/>
            <updated>2016-09-04T00:00:00+02:00</updated>
            <id>/blog/2016/09/04/Supporting-Zend-Service-Manager-Factories-for-V2-and-V3</id>
            <content type="html"><![CDATA[<p>When creating a module it can be useful to support Zend ServiceManager Version V2 and V3.
I dealt with this problem a few days ago: my module had to work in two application based - one based on Zend 2.4 and the
other one based on Zend 3.0. When looking at the <code>FactoryInterface</code> in both version, we easily see the problem:</p>

<pre><code class="php">namespace Zend\ServiceManager\Factory;

use Interop\Container\ContainerInterface;
use Interop\Container\Exception\ContainerException;
use Zend\ServiceManager\Exception\ServiceNotCreatedException;
use Zend\ServiceManager\Exception\ServiceNotFoundException;

interface FactoryInterface
{
    public function __invoke(ContainerInterface $container, $requestedName, array $options = null);
}
</code></pre>

<pre><code class="php">namespace Zend\ServiceManager;

interface FactoryInterface
{
    public function createService(ServiceLocatorInterface $serviceLocator);
}
</code></pre>

<p>As you can see, the Interface was moved into another Namespace - which was the right decision. But as a Module creator,
you can't implement both Interfaces. If you do so, one of the versions will always be missing and it leads into a 
PHP Fatal Error.</p>

<p>To solve the problem just implement none of the <code>FactoryInterface</code>'s and manually create the methods as seen in the 
example below:</p>

<pre><code class="php">namespace Foo;

class FooFactory
{
    // support for Zend Service Manager V3
    public function __invoke($container, $requestedName, array $options = null)
    {
        return new Foo($container-&gt;get(SomeDependency::class));
    }

    // support for Zend Service Manager V2
    public function createService($serviceLocator)
    {
        return $this-&gt;__invoke($serviceLocator, 'Foo\Foo');    
    }
}
</code></pre>

<p>Please notice, I also removed the type Hinting from the methods. This allows us to pass the ServiceManger V2 into the
<code>__invoke</code> method.</p>

<h2 id="why-dose-it-works">Why dose it works</h2>

<p>This is really simple. The ServiceManager checks in both versions if the instantiated Factory supports the required method.
If the method exists in the installed version, the ServiceManager assumes that the method is the factory method and executes it.</p>
]]></content>
        </entry>
    </feed>